{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "830143f3",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with `scikit-learn`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8447d0ed",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "In this notebook, we explore hyperparameter tuning methods, specifically `GridSearchCV` and `RandomizedSearchCV`, to optimize machine learning models in `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351b619",
   "metadata": {},
   "source": [
    "## 2. An Introduction to Grid Search\n",
    "\n",
    "Grid Search exhaustively searches over a specified parameter grid, testing each possible combination to find the best-performing parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05eccd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: LogisticRegression(C=100, max_iter=1000, penalty='l1', solver='liblinear')\n",
      "Best Parameters: {'C': 100, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Load the data\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target)\n",
    "\n",
    "# Initialize the model\n",
    "lr = LogisticRegression(solver=\"liblinear\", max_iter=1000)\n",
    "\n",
    "# Define the parameter grid\n",
    "parameters = {\"penalty\": [\"l1\", \"l2\"], \"C\": [1, 10, 100]}\n",
    "\n",
    "# Create the GridSearchCV model\n",
    "clf = GridSearchCV(lr, parameters)\n",
    "\n",
    "# Fit the model to find the best parameters\n",
    "clf.fit(X_train, y_train)\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Output the best model and parameters\n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Parameters:\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4296f4",
   "metadata": {},
   "source": [
    "## 3. Evaluating the Results of `GridSearchCV`\n",
    "\n",
    "After fitting `GridSearchCV`, we can access the best parameters and score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbdbfdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score (Cross-Validation): 0.9554856361149111\n",
      "Test Score: 0.9790209790209791\n"
     ]
    }
   ],
   "source": [
    "best_score = clf.best_score_\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(\"Best Score (Cross-Validation):\", best_score)\n",
    "print(\"Test Score:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6578a563",
   "metadata": {},
   "source": [
    "## 4. An Introduction to Random Search\n",
    "\n",
    "Unlike Grid Search, Random Search samples from a distribution of parameter values, which can be more efficient for large parameter spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed60e978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=76.29336604445899, max_iter=1000, penalty='l1',\n",
      "                   solver='liblinear')\n",
      "{'C': 76.29336604445899, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "# Load the data set\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Create distributions to draw hyperparameters from\n",
    "distributions = {\"penalty\": [\"l1\", \"l2\"], \"C\": uniform(loc=0, scale=100)}\n",
    "\n",
    "# The logistic regression model\n",
    "lr = LogisticRegression(solver=\"liblinear\", max_iter=1000)\n",
    "\n",
    "# Create a RandomizedSearchCV model\n",
    "clf = RandomizedSearchCV(lr, distributions, n_iter=8)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "best_model = clf.best_estimator_\n",
    "print(best_model)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40662379",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Results of `RandomizedSearchCV`\n",
    "\n",
    "After fitting `RandomizedSearchCV`, we can access the best parameters and score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb3d246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9601367989056089\n",
      "0.9790209790209791\n",
      "           C penalty     score\n",
      "0  26.100009      l2  0.948399\n",
      "1  76.293366      l1  0.960137\n",
      "2  10.042309      l2  0.943721\n",
      "3  42.513174      l1  0.950780\n",
      "4   3.738885      l2  0.950752\n",
      "5  26.036038      l1  0.955458\n",
      "6  73.942583      l1  0.960137\n",
      "7   8.745556      l1  0.950752\n"
     ]
    }
   ],
   "source": [
    "best_score = clf.best_score_\n",
    "test_score = clf.score(X_test, y_test)\n",
    "print(best_score)\n",
    "print(test_score)\n",
    "\n",
    "import pandas as pd\n",
    "hyperparameter_values = pd.DataFrame(clf.cv_results_[\"params\"])\n",
    "randomsearch_scores = pd.DataFrame(\n",
    "    clf.cv_results_[\"mean_test_score\"], columns=[\"score\"]\n",
    ")\n",
    "df = pd.concat([hyperparameter_values, randomsearch_scores], axis=1)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
